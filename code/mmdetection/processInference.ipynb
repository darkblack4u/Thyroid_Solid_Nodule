{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/Thyroid_Solid_Nodule/code/mmdetection/mmdet/apis/inference.py:41: UserWarning: Class names are not saved in the checkpoint's meta data, use COCO classes by default.\n",
      "  warnings.warn('Class names are not saved in the checkpoint\\'s '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mmdetection/lib/python3.6/site-packages/pycocotools/coco.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug/annotations/images.json' mode='r' encoding='UTF-8'>\n",
      "  dataset = json.load(open(annotation_file, 'r'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/Thyroid_Solid_Nodule/code/mmdetection/mmdet/core/post_processing/bbox_nms.py:52: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629416375/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  labels = valid_mask.nonzero()[:, 1]\n",
      "/root/miniconda3/envs/mmdetection/lib/python3.6/site-packages/ipykernel_launcher.py:70: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n",
      "(768, 1024, 3)\n",
      "(200, 272)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmcv import Config\n",
    "import copy\n",
    "import os.path as osp\n",
    "import os\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pylab import *\n",
    "from matplotlib import cm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5\"\n",
    "\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_chenzhou.py')\n",
    "cfg.work_dir = 'logs/faster_rcnn_r50_fpn_1x_chenzhou/'\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.seed = 0\n",
    "cfg.total_epochs = 50\n",
    "cfg.log_config.interval = 1000\n",
    "\n",
    "checkpoint = 'logs/faster_rcnn_r50_fpn_1x_chenzhou/latest.pth'\n",
    "\n",
    "model = init_detector(cfg, checkpoint, device='cuda:1')\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "path = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug/tests/'\n",
    "result_path = cfg.work_dir + '/tests/'\n",
    "\n",
    "if os.path.exists(result_path + \"/result/\") == False:\n",
    "    os.makedirs(result_path + \"/result/\")\n",
    "if os.path.exists(result_path + \"/featuremap/\") == False:\n",
    "    os.makedirs(result_path + \"/featuremap/\")\n",
    "\n",
    "# # Use the detector to do inference\n",
    "# img = path + 'A4B2C3D3E4_106THY4620180823092452358T.jpg'\n",
    "# result, x = inference_detector(model, img)\n",
    "\n",
    "# # Let's plot the result\n",
    "# show_result_pyplot(model, img, result, score_thr=0.3)\n",
    "\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap(['royalblue', 'cyan', 'yellow', 'orange'])\n",
    "cmap.set_over('red')\n",
    "cmap.set_under('blue')\n",
    "\n",
    "# bounds = [0,2,4,8,10]\n",
    "bounds = [-1,2,5,8,11]\n",
    "# bounds = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "images=[]\n",
    "for root, dirs, files in os.walk(os.path.abspath(path)):\n",
    "    for file in files:\n",
    "        img = mmcv.imread(path + file)\n",
    "        result, x = inference_detector(model, img)\n",
    "        out_img = model.show_result(img, result, score_thr=0.3, show=False)\n",
    "        mmcv.imwrite(mmcv.bgr2rgb(out_img), result_path + '/result/' + file)\n",
    "        img_np=x[0].data.cpu().numpy()\n",
    "        feature_map = np.squeeze(img_np, axis=0)\n",
    "        feature_map_combination = []\n",
    "        num_pic = feature_map.shape[0]\n",
    "        for i in range(0, num_pic):\n",
    "            feature_map_split = feature_map[i, :, :]\n",
    "            feature_map_combination.append(feature_map_split)\n",
    "        feature_map_sum = sum(ele for ele in feature_map_combination)\n",
    "#         images.append(feature_map_sum)\n",
    "#         plt.figure()\n",
    "# #         plt.imshow(feature_map_sum * 1000, cmap=cmap)  \n",
    "#         plt.imshow(feature_map_sum, cmap=cmap, norm=norm)\n",
    "# #         plt.show()\n",
    "#         plt.savefig(result_path + '/featuremap/' + file, bbox_inches ='tight') \n",
    "        print(img.shape)\n",
    "        print(feature_map_sum.shape)\n",
    "        normalizedImg = np.zeros(feature_map_sum.shape) \n",
    "        normalizedImg = cv2.normalize(feature_map_sum, normalizedImg, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX) \n",
    "        normalizedImg = cv2.applyColorMap(normalizedImg.astype(np.uint8), cv2.COLORMAP_HSV)\n",
    "        normalizedImg = cv2.resize(normalizedImg, (img.shape[1],img.shape[0]))\n",
    "#         plt.imshow(feature_map_sum, cmap=cmap, norm = matplotlib.colors.Normalize(-10, 10, clip = False))\n",
    "#         plt.savefig(result_path + '/featuremap/' + file)\n",
    "#         print(feature_map_sum)\n",
    "#         minVals = feature_map_sum.min(0)\n",
    "#         maxVals = feature_map_sum.max(0)\n",
    "#         ranges = maxVals - minVals\n",
    "#         normData = np.zeros(np.shape(feature_map_sum))\n",
    "#         m = feature_map_sum.shape[0]\n",
    "#         normData = feature_map_sum - np.tile(minVals, (m, 1))\n",
    "#         normData = normData/np.tile(ranges, (m, 1))\n",
    "#         normData = normData * 255\n",
    "#         print(normData)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(normData)\n",
    "#         plt.savefig(result_path + '/featuremap/' + file)        \n",
    "        mmcv.imwrite(normalizedImg, result_path + '/featuremap/' + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import models, transforms\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pylab import *\n",
    "\n",
    "# print(x[0].data.cpu().numpy())\n",
    "# img_np=x[0].data.cpu().numpy()\n",
    "# print(np.squeeze(img_np, axis=0))\n",
    "# feature_map = np.squeeze(img_np, axis=0)\n",
    "# print(feature_map.shape)\n",
    "# feature_map_combination = []\n",
    "# plt.figure()\n",
    "# num_pic = feature_map.shape[0]\n",
    "\n",
    "# def get_row_col(num_pic):\n",
    "#     squr = num_pic ** 0.5\n",
    "#     row = round(squr)\n",
    "#     col = row + 1 if squr - row > 0 else row\n",
    "#     return row, col\n",
    "\n",
    "# row, col = get_row_col(num_pic)\n",
    "\n",
    "# for i in range(0, num_pic):\n",
    "#     feature_map_split = feature_map[i, :, :]\n",
    "#     feature_map_combination.append(feature_map_split)\n",
    "# #     plt.subplot(row, col, i + 1)\n",
    "# #     plt.imshow(feature_map_split)\n",
    "# #     axis('off')\n",
    "# #     title('feature_map_{}'.format(i))\n",
    " \n",
    "# # plt.savefig('feature_map.png')\n",
    "# # plt.show()\n",
    " \n",
    "# # 各个特征图按1：1 叠加\n",
    "# feature_map_sum = sum(ele for ele in feature_map_combination)\n",
    "# plt.imshow(feature_map_sum)\n",
    "# plt.savefig('feature_map.png')\n",
    "# plt.show()\n",
    "# # from torchvision import models, transforms\n",
    "# # # transforms.ToTensor()\n",
    "# # transform1 = transforms.Compose([\n",
    "# #     transforms.ToPILImage, # range [0, 255] -> [0.0,1.0]\n",
    "# #     ]\n",
    "# # )\n",
    "# # img_np1=transforms.ToPILImage()(img_np).convert('RGB')\n",
    "# # print(img_np1)\n",
    "# # img_np1.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('mmdetection': conda)",
   "language": "python",
   "name": "python361164bitmmdetectioncondac5e20e32b3c64899be2ee20da743e85a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
