{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/Thyroid_Solid_Nodule/code/mmdetection/mmdet/apis/inference.py:41: UserWarning: Class names are not saved in the checkpoint's meta data, use COCO classes by default.\n",
      "  warnings.warn('Class names are not saved in the checkpoint\\'s '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mmdetection/lib/python3.6/site-packages/pycocotools/coco.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug/annotations/pseudo_images.json' mode='r' encoding='UTF-8'>\n",
      "  dataset = json.load(open(annotation_file, 'r'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.62s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/Thyroid_Solid_Nodule/code/mmdetection/mmdet/core/post_processing/bbox_nms.py:52: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629416375/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  labels = valid_mask.nonzero()[:, 1]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Got <class 'PIL.Image.Image'>, but expected numpy array or torch tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5fa440ae001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mout_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 执行close立即刷新，否则将每120秒自动刷新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbgr2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/result/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mmdetection/lib/python3.6/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_image\u001b[0;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 608\u001b[0;31m             image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mmdetection/lib/python3.6/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[1;32m    281\u001b[0m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_HWC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# Do not assume that user passes in values in [0, 255], use data type to detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mmdetection/lib/python3.6/site-packages/tensorboardX/x2num.py\u001b[0m in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     raise NotImplementedError(\n\u001b[0;32m---> 36\u001b[0;31m         'Got {}, but expected numpy array or torch tensor.'.format(type(x)))\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Got <class 'PIL.Image.Image'>, but expected numpy array or torch tensor."
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmcv import Config\n",
    "import copy\n",
    "import os.path as osp\n",
    "import os\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pylab import *\n",
    "from matplotlib import cm\n",
    "from tensorboardX import SummaryWriter\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_chenzhou.py')\n",
    "# cfg = Config.fromfile('./configs/faster_rcnn/xiaohei_faster_rcnn_r50_fpn_1x_chenzhou.py')\n",
    "cfg.work_dir = 'logs/faster_rcnn_r50_fpn_1x_chenzhou_202009291508/'\n",
    "# cfg.work_dir = 'logs/xiaohei_faster_rcnn_r50_fpn_1x_chenzhou_202009291506/'\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.seed = 0\n",
    "cfg.total_epochs = 50\n",
    "cfg.log_config.interval = 1000\n",
    "\n",
    "checkpoint = cfg.work_dir + 'epoch_12.pth'\n",
    "\n",
    "# checkpoint = 'logs/xiaohei_faster_rcnn_r50_fpn_1x_chenzhou_202009291506/epoch_12.pth'\n",
    "\n",
    "model = init_detector(cfg, checkpoint, device='cuda:1')\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "# path = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug/tests/'\n",
    "path = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou/image/'\n",
    "\n",
    "result_path = cfg.work_dir + '/tests/'\n",
    "\n",
    "if os.path.exists(result_path + \"/result/\") == False:\n",
    "    os.makedirs(result_path + \"/result/\")\n",
    "if os.path.exists(result_path + \"/featuremap/\") == False:\n",
    "    os.makedirs(result_path + \"/featuremap/\")\n",
    "\n",
    "# # Use the detector to do inference\n",
    "# img = path + 'A4B2C3D3E4_106THY4620180823092452358T.jpg'\n",
    "# result, x = inference_detector(model, img)\n",
    "\n",
    "# # Let's plot the result\n",
    "# show_result_pyplot(model, img, result, score_thr=0.3)\n",
    "\n",
    "writer = SummaryWriter(log_dir=cfg.work_dir + 'tensorboardX/', comment='image') # 这里的logs要与--logdir的参数一样\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap(['royalblue', 'cyan', 'yellow', 'orange'])\n",
    "cmap.set_over('red')\n",
    "cmap.set_under('blue')\n",
    "\n",
    "# bounds = [0,2,4,8,10]\n",
    "bounds = [-1,2,5,8,11]\n",
    "# bounds = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "images=[]\n",
    "for root, dirs, files in os.walk(os.path.abspath(path)):\n",
    "    for file in files:\n",
    "        if file.startswith('A4'):\n",
    "            img = mmcv.imread(path + file)\n",
    "#         result, x = inference_detector(model, img)\n",
    "            result = inference_detector(model, img)\n",
    "\n",
    "            out_img = model.show_result(img, result, score_thr=0.8, show=False)\n",
    "            mmcv.imwrite(mmcv.bgr2rgb(out_img), result_path + '/result/' + file)\n",
    "        #########################################################\n",
    "#         img_np=x[0].data.cpu().numpy()\n",
    "#         feature_map = np.squeeze(img_np, axis=0)\n",
    "#         feature_map_combination = []\n",
    "#         num_pic = feature_map.shape[0]\n",
    "#         for i in range(0, num_pic):\n",
    "#             feature_map_split = feature_map[i, :, :]\n",
    "#             feature_map_combination.append(feature_map_split)\n",
    "#         feature_map_sum = sum(ele for ele in feature_map_combination)\n",
    "# #         images.append(feature_map_sum)\n",
    "# #         plt.figure()\n",
    "# # #         plt.imshow(feature_map_sum * 1000, cmap=cmap)  \n",
    "# #         plt.imshow(feature_map_sum, cmap=cmap, norm=norm)\n",
    "# # #         plt.show()\n",
    "# #         plt.savefig(result_path + '/featuremap/' + file, bbox_inches ='tight') \n",
    "#         print(img.shape)\n",
    "#         print(feature_map_sum.shape)\n",
    "#         normalizedImg = np.zeros(feature_map_sum.shape) \n",
    "#         normalizedImg = cv2.normalize(feature_map_sum, normalizedImg, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX) \n",
    "#         normalizedImg = cv2.applyColorMap(normalizedImg.astype(np.uint8), cv2.COLORMAP_HSV)\n",
    "#         normalizedImg = cv2.resize(normalizedImg, (img.shape[1],img.shape[0]))\n",
    "        #########################################################\n",
    "#         plt.imshow(feature_map_sum, cmap=cmap, norm = matplotlib.colors.Normalize(-10, 10, clip = False))\n",
    "#         plt.savefig(result_path + '/featuremap/' + file)\n",
    "#         print(feature_map_sum)\n",
    "#         minVals = feature_map_sum.min(0)\n",
    "#         maxVals = feature_map_sum.max(0)\n",
    "#         ranges = maxVals - minVals\n",
    "#         normData = np.zeros(np.shape(feature_map_sum))\n",
    "#         m = feature_map_sum.shape[0]\n",
    "#         normData = feature_map_sum - np.tile(minVals, (m, 1))\n",
    "#         normData = normData/np.tile(ranges, (m, 1))\n",
    "#         normData = normData * 255\n",
    "#         print(normData)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(normData)\n",
    "#         plt.savefig(result_path + '/featuremap/' + file) \n",
    "#########################################################\n",
    "#         mmcv.imwrite(normalizedImg, result_path + '/featuremap/' + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from torchvision import models, transforms\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pylab import *\n",
    "\n",
    "# print(x[0].data.cpu().numpy())\n",
    "# img_np=x[0].data.cpu().numpy()\n",
    "# print(np.squeeze(img_np, axis=0))\n",
    "# feature_map = np.squeeze(img_np, axis=0)\n",
    "# print(feature_map.shape)\n",
    "# feature_map_combination = []\n",
    "# plt.figure()\n",
    "# num_pic = feature_map.shape[0]\n",
    "\n",
    "# def get_row_col(num_pic):\n",
    "#     squr = num_pic ** 0.5\n",
    "#     row = round(squr)\n",
    "#     col = row + 1 if squr - row > 0 else row\n",
    "#     return row, col\n",
    "\n",
    "# row, col = get_row_col(num_pic)\n",
    "\n",
    "# for i in range(0, num_pic):\n",
    "#     feature_map_split = feature_map[i, :, :]\n",
    "#     feature_map_combination.append(feature_map_split)\n",
    "# #     plt.subplot(row, col, i + 1)\n",
    "# #     plt.imshow(feature_map_split)\n",
    "# #     axis('off')\n",
    "# #     title('feature_map_{}'.format(i))\n",
    " \n",
    "# # plt.savefig('feature_map.png')\n",
    "# # plt.show()\n",
    " \n",
    "# # 各个特征图按1：1 叠加\n",
    "# feature_map_sum = sum(ele for ele in feature_map_combination)\n",
    "# plt.imshow(feature_map_sum)\n",
    "# plt.savefig('feature_map.png')\n",
    "# plt.show()\n",
    "# # from torchvision import models, transforms\n",
    "# # # transforms.ToTensor()\n",
    "# # transform1 = transforms.Compose([\n",
    "# #     transforms.ToPILImage, # range [0, 255] -> [0.0,1.0]\n",
    "# #     ]\n",
    "# # )\n",
    "# # img_np1=transforms.ToPILImage()(img_np).convert('RGB')\n",
    "# # print(img_np1)\n",
    "# # img_np1.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('mmdetection': conda)",
   "language": "python",
   "name": "python361164bitmmdetectioncondac5e20e32b3c64899be2ee20da743e85a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
