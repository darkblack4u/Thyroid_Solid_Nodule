{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从Mask文件中输出Box/Mask信息，生成COCO json文件\n",
    "输出：COCO json\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "\n",
    "# Label ids of TN-SCUI2020 Dataset\n",
    "nodule_id = 1\n",
    "outlier_id = 0\n",
    "category_ids = {\n",
    "    '(255, 255, 255)': nodule_id,\n",
    "    '(1, 1, 1)': nodule_id,\n",
    "    '(0, 0, 0)': outlier_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sub_masks(mask_image, width, height):\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            pixel = mask_image.getpixel((x, y))[:3]\n",
    "            newpixel = ((pixel[0] > 128) * 255, (pixel[1] > 128) * 255, (pixel[2] > 128) * 255)\n",
    "\n",
    "            # If the pixel is not black...\n",
    "            if newpixel != (0, 0, 0):\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(newpixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width, height))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "#                 sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "                sub_masks[pixel_str].putpixel((x, y),1)\n",
    "\n",
    "    return sub_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sub_mask_annotation(sub_mask):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "\n",
    "    polygons = []\n",
    "    j = 0\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "\n",
    "        if(poly.is_empty):\n",
    "            # Go to next iteration, dont save empty values in list\n",
    "            continue\n",
    "\n",
    "        polygons.append(poly)\n",
    "\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def absolute_file_paths(image_path, mask_path, keyword):\n",
    "    mask_images = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.abspath(mask_path)):\n",
    "        for file in files:\n",
    "            if 'ground' in file:\n",
    "                dstFile = file.replace('_groundtruth_(1)_','').replace('.jpg_','_')\n",
    "                os.rename(mask_path + '/'+ file, mask_path + '/'+ dstFile)\n",
    "    \n",
    "    for root, dirs, files in os.walk(os.path.abspath(image_path)):\n",
    "        for file in files:\n",
    "            if 'original' in file:\n",
    "                dstFile = file.replace('_original_','_').replace('.jpg_','_')\n",
    "                os.rename(image_path + '/'+ file, image_path + '/'+ dstFile)\n",
    "                \n",
    "    for root, dirs, files in os.walk(os.path.abspath(image_path)):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "#                 if file.startswith(keyword):\n",
    "#                 if '-' not in file:\n",
    "                    mask_images.append(os.path.join(mask_path, file))\n",
    "    return mask_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_annotation(file_name, width, height, image_id):\n",
    "    images = {\n",
    "        'file_name': file_name,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'id': image_id\n",
    "    }\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get 'images' and 'annotations' info\n",
    "def images_annotations_info(image_path, mask_path, keyword, folder_id):\n",
    "    # This id will be automatically increased as we go\n",
    "    annotation_id = 1\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    # Get absolute paths of all files in a directory\n",
    "    mask_images = absolute_file_paths(image_path, mask_path, keyword)\n",
    "\n",
    "    length = len(mask_images)\n",
    "    \n",
    "    for image_id, mask_image in enumerate(mask_images, folder_id):\n",
    "        file_name = image_path + '/' + os.path.basename(mask_image).split('.')[0] + \".jpg\"\n",
    "        if image_id % 100 is 0:\n",
    "            print(str(image_id) + '/' + str(length))\n",
    "\n",
    "#         file_name = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou/mask' + os.path.basename(mask_image).split('.')[0] + \".jpg\"\n",
    "#         mask_image_open = cv2.imread(mask_image)\n",
    "#         mask_image_open = (mask_image_open > 128) * 255\n",
    "        # image shape\n",
    "        mask_image_open = Image.open(mask_image)\n",
    "        w, h = mask_image_open.size\n",
    "\n",
    "        # 'images' info\n",
    "        image = create_image_annotation(os.path.basename(mask_image).split('.')[0] + \".jpg\", w, h, image_id)\n",
    "        images.append(image)\n",
    "\n",
    "        sub_masks = create_sub_masks(mask_image_open.convert('RGBA'), w, h)\n",
    "        for color, sub_mask in sub_masks.items():\n",
    "            category_id = category_ids[color]\n",
    "\n",
    "            # 'annotations' info\n",
    "            sub_mask =  np.array(sub_mask)\n",
    "            polygons = create_sub_mask_annotation(sub_mask)\n",
    "\n",
    "            for i in range(len(polygons)):\n",
    "                min_x, min_y, max_x, max_y = polygons[i].bounds\n",
    "                width = max_x - min_x\n",
    "                height = max_y - min_y\n",
    "                bbox = (int(min_x), int(min_y), int(width), int(height))\n",
    "                area = polygons[i].area\n",
    "                segmentation = []\n",
    "                try:\n",
    "                    segmentation = np.array(polygons[i].exterior.coords).ravel().tolist()\n",
    "                except:\n",
    "                    print(str(image_id) + '/' + str(length) + ':ERROR#' + os.path.basename(mask_image).split('.')[0])\n",
    "                annotation = {\n",
    "                    'segmentation': [list(int(_) for _ in segmentation)],\n",
    "                    'area': int(area),\n",
    "                    'iscrowd': int(0),\n",
    "                    'image_id': int(image_id),\n",
    "                    'bbox': bbox,\n",
    "                    'category_id': int(category_id),\n",
    "                    'id': int(annotation_id)\n",
    "                }\n",
    "                annotations.append(annotation)\n",
    "                annotation_id += 1\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成A1A2A3A4json文件\n",
    "#     for keyword in ['train', 'val']:\n",
    "TRAIN_PATH = '/root/workspace/TN-SCUI2020-Challenge/data/train'\n",
    "ORIGIN_PATH = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug'\n",
    "MASK_PATH = ORIGIN_PATH + '/mask'\n",
    "# for keyword in ['val', 'test', 'train']:\n",
    "for folder_id, keyword in enumerate(['A1', 'A2', 'A3', 'A4'], 0):\n",
    "# for keyword in ['images']:\n",
    "    print(str(keyword) + ': START')\n",
    "#     IMAGE_PATH = ORIGIN_PATH + '/{}'.format(keyword)\n",
    "    IMAGE_PATH = ORIGIN_PATH + '/images'\n",
    "    dataset['images'], dataset['annotations'] = images_annotations_info(IMAGE_PATH, MASK_PATH, keyword, folder_id * 100000)\n",
    "    with open(ORIGIN_PATH + '/annotations/' + '{}'.format(keyword) + '.json', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "    print(str(keyword) + ': END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并A1A2A3A4json文件\n",
    "\n",
    "#     for keyword in ['train', 'val']:\n",
    "TRAIN_PATH = '/root/workspace/TN-SCUI2020-Challenge/data/train'\n",
    "ORIGIN_PATH = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug'\n",
    "MASK_PATH = ORIGIN_PATH + '/mask'\n",
    "total_dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "total_dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "total_dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "for keyword in ['A1', 'A2', 'A3', 'A4']:\n",
    "    with open(ORIGIN_PATH + '/annotations/' + '{}'.format(keyword) + '.json', 'r') as infile:\n",
    "        djson = json.loads(infile.read())\n",
    "        for entity in djson['images']:\n",
    "            total_dataset['images'].append({\n",
    "                'file_name': entity['file_name'], \n",
    "                'id': int(entity['id']), \n",
    "                'width': int(entity['width']), \n",
    "                'height': int(entity['height'])})\n",
    "        for entity in djson['annotations']:\n",
    "            total_dataset['annotations'].append({\n",
    "               'area': entity['area'],\n",
    "               'bbox': list(int(_) for _ in entity['bbox']),\n",
    "               'category_id': int(entity['category_id']),\n",
    "               'id': int(entity['id']),\n",
    "               'image_id': int(entity['image_id']),\n",
    "               'iscrowd': int(entity['iscrowd']),\n",
    "                    # mask, 矩形是从左上角点按顺时针的四个顶点\n",
    "               'segmentation': [list(int(_) for _ in entity['segmentation'][0])]})\n",
    "#         total_dataset['images'].append(djson['images'])\n",
    "#         total_dataset['annotations'].append(djson['annotations'])\n",
    "\n",
    "with open(ORIGIN_PATH + '/annotations/' + 'images.json', 'w') as outfile:\n",
    "    json.dump(total_dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests: START\n",
      "0/15\n",
      "tests: END\n",
      "validations: START\n",
      "0/15\n",
      "validations: END\n"
     ]
    }
   ],
   "source": [
    "# 处理tests和validations目录\n",
    "\n",
    "for keyword in ['tests', 'validations']:\n",
    "# for keyword in ['images']:\n",
    "    sub_dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "    sub_dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "    sub_dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "    print(str(keyword) + ': START')\n",
    "    IMAGE_PATH = ORIGIN_PATH + '/{}'.format(keyword)\n",
    "#     IMAGE_PATH = ORIGIN_PATH + '/images'\n",
    "    sub_dataset['images'], sub_dataset['annotations'] = images_annotations_info(IMAGE_PATH, MASK_PATH, keyword, 0 * 100000)\n",
    "    with open(ORIGIN_PATH + '/annotations/' + '{}'.format(keyword) + '.json', 'w') as outfile:\n",
    "        json.dump(sub_dataset, outfile)\n",
    "    print(str(keyword) + ': END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('mmdetection': conda)",
   "language": "python",
   "name": "python361164bitmmdetectioncondac5e20e32b3c64899be2ee20da743e85a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
