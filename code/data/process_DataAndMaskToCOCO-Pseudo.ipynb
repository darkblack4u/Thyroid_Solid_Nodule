{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从Mask文件中输出Box/Pseudo Mask（椭圆）信息，生成COCO json文件\n",
    "输出：COCO json\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "\n",
    "# Label ids of TN-SCUI2020 Dataset\n",
    "nodule_id = 1\n",
    "outlier_id = 0\n",
    "category_ids = {\n",
    "    '(255, 255, 255)': nodule_id,\n",
    "    '(1, 1, 1)': nodule_id,\n",
    "    '(0, 0, 0)': outlier_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sub_masks(mask_image, width, height):\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            pixel = mask_image.getpixel((x, y))[:3]\n",
    "            newpixel = ((pixel[0] > 128) * 255, (pixel[1] > 128) * 255, (pixel[2] > 128) * 255)\n",
    "\n",
    "            # If the pixel is not black...\n",
    "            if newpixel != (0, 0, 0):\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(newpixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width, height))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "#                 sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "                sub_masks[pixel_str].putpixel((x, y),1)\n",
    "\n",
    "    return sub_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sub_mask_annotation(sub_mask):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "\n",
    "    polygons = []\n",
    "    j = 0\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "\n",
    "        if(poly.is_empty):\n",
    "            # Go to next iteration, dont save empty values in list\n",
    "            continue\n",
    "\n",
    "        polygons.append(poly)\n",
    "\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def absolute_file_paths(image_path, mask_path, keyword, is_sub = True):\n",
    "    mask_images = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.abspath(mask_path)):\n",
    "        for file in files:\n",
    "            if 'ground' in file:\n",
    "                dstFile = file.replace('_groundtruth_(1)_','').replace('.jpg_','_')\n",
    "                os.rename(mask_path + '/'+ file, mask_path + '/'+ dstFile)\n",
    "    \n",
    "    for root, dirs, files in os.walk(os.path.abspath(image_path)):\n",
    "        for file in files:\n",
    "            if 'original' in file:\n",
    "                dstFile = file.replace('_original_','_').replace('.jpg_','_')\n",
    "                os.rename(image_path + '/'+ file, image_path + '/'+ dstFile)\n",
    "                \n",
    "    for root, dirs, files in os.walk(os.path.abspath(image_path)):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "                if file.startswith(keyword) or not is_sub:\n",
    "#                 if '-' not in file:\n",
    "                    mask_images.append(os.path.join(mask_path, file))\n",
    "    return mask_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_annotation(file_name, width, height, image_id):\n",
    "    images = {\n",
    "        'file_name': file_name,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'id': image_id\n",
    "    }\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get 'images' and 'annotations' info\n",
    "def images_annotations_info(image_path, mask_path, keyword, folder_id, is_sub = True):\n",
    "    # This id will be automatically increased as we go\n",
    "    annotation_id = 1\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    # Get absolute paths of all files in a directory\n",
    "    mask_images = absolute_file_paths(image_path, mask_path, keyword, is_sub)\n",
    "\n",
    "    length = len(mask_images)\n",
    "    \n",
    "    for image_id, mask_image in enumerate(mask_images, folder_id):\n",
    "        file_name = image_path + '/' + os.path.basename(mask_image).split('.')[0] + \".jpg\"\n",
    "        if image_id % 100 is 0:\n",
    "            print(str(image_id) + '/' + str(length))\n",
    "\n",
    "#         file_name = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou/mask' + os.path.basename(mask_image).split('.')[0] + \".jpg\"\n",
    "#         mask_image_open = cv2.imread(mask_image)\n",
    "#         mask_image_open = (mask_image_open > 128) * 255\n",
    "        # image shape\n",
    "        mask_image_open = Image.open(mask_image)\n",
    "        w, h = mask_image_open.size\n",
    "\n",
    "        # 'images' info\n",
    "        image = create_image_annotation(os.path.basename(mask_image).split('.')[0] + \".jpg\", w, h, image_id)\n",
    "        images.append(image)\n",
    "\n",
    "        sub_masks = create_sub_masks(mask_image_open.convert('RGBA'), w, h)\n",
    "        for color, sub_mask in sub_masks.items():\n",
    "            category_id = category_ids[color]\n",
    "\n",
    "            # 'annotations' info\n",
    "            sub_mask =  np.array(sub_mask)\n",
    "            polygons = create_sub_mask_annotation(sub_mask)\n",
    "\n",
    "            for i in range(len(polygons)):\n",
    "                peudo_mask=np.zeros(mask_image_open.size).astype('uint8')\n",
    "                min_x, min_y, max_x, max_y = polygons[i].bounds\n",
    "                width = max_x - min_x\n",
    "                height = max_y - min_y\n",
    "                bbox = (int(min_x), int(min_y), int(width), int(height))\n",
    "                hcenter = int((min_y + max_y) / 2)\n",
    "                lcenter = int((min_x + max_x) / 2)\n",
    "                peudo_mask = cv2.ellipse(peudo_mask, (lcenter, hcenter), (int(width/2), int(height/2)), 0, 0, 360, color=(255,255,255), thickness=-1, lineType=0) #画椭圆\n",
    "                peudo_polygons = create_sub_mask_annotation(peudo_mask)\n",
    "                area = polygons[i].area\n",
    "                segmentation = []\n",
    "                try:\n",
    "                    peudo_mask = cv2.ellipse(peudo_mask, (lcenter, hcenter), (int(width/2), int(height/2)), 0, 0, 360, color=(255,255,255), thickness=-1, lineType=0) #画椭圆\n",
    "                    peudo_polygons = create_sub_mask_annotation(peudo_mask)\n",
    "                    area = peudo_polygons[0].area\n",
    "                    segmentation = np.array(peudo_polygons[0].exterior.coords).ravel().tolist()\n",
    "                except:\n",
    "                    print(str(image_id) + '/' + str(length) + ':ERROR#' + os.path.basename(mask_image).split('.')[0])\n",
    "                else:\n",
    "                    annotation = {\n",
    "                        'segmentation': [list(int(_) for _ in segmentation)],\n",
    "                        'area': int(area),\n",
    "                        'iscrowd': int(0),\n",
    "                        'image_id': int(image_id),\n",
    "                        'bbox': bbox,\n",
    "                        'category_id': int(category_id),\n",
    "                        'id': int(annotation_id)\n",
    "                    }\n",
    "                    annotations.append(annotation)\n",
    "                    annotation_id += 1\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1: START\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f6109703417d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     IMAGE_PATH = ORIGIN_PATH + '/{}'.format(keyword)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mIMAGE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mORIGIN_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_annotations_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_id\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIGIN_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/annotations/pseudo_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-08b405bac35e>\u001b[0m in \u001b[0;36mimages_annotations_info\u001b[0;34m(image_path, mask_path, keyword, folder_id, is_sub)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get absolute paths of all files in a directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmask_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsolute_file_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f4f1a4781679>\u001b[0m in \u001b[0;36mabsolute_file_paths\u001b[0;34m(image_path, mask_path, keyword, is_sub)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmask_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'ground'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mmdetection/lib/python3.6/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 生成A1A2A3A4json文件\n",
    "#     for keyword in ['train', 'val']:\n",
    "TRAIN_PATH = '/root/workspace/TN-SCUI2020-Challenge/data/train'\n",
    "ORIGIN_PATH = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug'\n",
    "MASK_PATH = ORIGIN_PATH + '/mask'\n",
    "# for keyword in ['val', 'test', 'train']:\n",
    "for folder_id, keyword in enumerate(['A1', 'A2', 'A3', 'A4'], 0):\n",
    "# for keyword in ['images']:\n",
    "    print(str(keyword) + ': START')\n",
    "#     IMAGE_PATH = ORIGIN_PATH + '/{}'.format(keyword)\n",
    "    IMAGE_PATH = ORIGIN_PATH + '/images'\n",
    "    dataset['images'], dataset['annotations'] = images_annotations_info(IMAGE_PATH, MASK_PATH, keyword, folder_id * 100000)\n",
    "    with open(ORIGIN_PATH + '/annotations/pseudo_' + '{}'.format(keyword) + '.json', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "    print(str(keyword) + ': END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并A1A2A3A4json文件\n",
    "\n",
    "#     for keyword in ['train', 'val']:\n",
    "TRAIN_PATH = '/root/workspace/TN-SCUI2020-Challenge/data/train'\n",
    "ORIGIN_PATH = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug'\n",
    "MASK_PATH = ORIGIN_PATH + '/mask'\n",
    "total_dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "total_dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "total_dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "for keyword in ['A1', 'A2', 'A3', 'A4']:\n",
    "    entitylist = {}\n",
    "    with open(ORIGIN_PATH + '/annotations/pseudo_' + '{}'.format(keyword) + '.json', 'r') as infile:\n",
    "        djson = json.loads(infile.read())\n",
    "        for entity in djson['images']:\n",
    "            total_dataset['images'].append({\n",
    "                'file_name': entity['file_name'], \n",
    "                'id': int(entity['id']), \n",
    "                'width': int(entity['width']), \n",
    "                'height': int(entity['height'])})\n",
    "        for entity in djson['annotations']:\n",
    "            if len(entity['segmentation'][0]) is not 0:\n",
    "                subdict = {\n",
    "                    'area': entity['area'],\n",
    "                    'bbox': list(int(_) for _ in entity['bbox']),\n",
    "                    'category_id': int(entity['category_id']),\n",
    "                    'id': int(entity['id']),\n",
    "                    'image_id': int(entity['image_id']),\n",
    "                    'iscrowd': int(entity['iscrowd']),\n",
    "                         # mask, 矩形是从左上角点按顺时针的四个顶点\n",
    "                    'segmentation': [list(int(_) for _ in entity['segmentation'][0])]}\n",
    "                if int(entity['image_id']) not in entitylist.keys():\n",
    "                    entitylist[int(entity['image_id'])] = subdict # 添加\n",
    "                else:\n",
    "                    if entitylist[int(entity['image_id'])]['area'] < entity['area']:\n",
    "                        entitylist[int(entity['image_id'])] = subdict # 添加\n",
    "        for key,values in  entitylist.items():\n",
    "            total_dataset['annotations'].append(values)\n",
    "\n",
    "#         total_dataset['images'].append(djson['images'])\n",
    "#         total_dataset['annotations'].append(djson['annotations'])\n",
    "\n",
    "with open(ORIGIN_PATH + '/annotations/pseudo_' + 'images.json', 'w') as outfile:\n",
    "    json.dump(total_dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理tests和validations目录\n",
    "TRAIN_PATH = '/root/workspace/TN-SCUI2020-Challenge/data/train'\n",
    "ORIGIN_PATH = '/root/workspace/Thyroid_Solid_Nodule/data/preprocess/chenzhou_aug'\n",
    "MASK_PATH = ORIGIN_PATH + '/mask'\n",
    "for keyword in ['tests', 'validations']:\n",
    "# for keyword in ['images']:\n",
    "    sub_dataset = {'categories':[],'images':[],'annotations':[]}\n",
    "    sub_dataset['categories'].append({'id': 1, 'name': 'nodule', 'supercategory': 'mark'})\n",
    "    sub_dataset['categories'].append({'id': 0, 'name': 'outlier', 'supercategory': 'mark'})\n",
    "    print(str(keyword) + ': START')\n",
    "    IMAGE_PATH = ORIGIN_PATH + '/{}'.format(keyword)\n",
    "#     IMAGE_PATH = ORIGIN_PATH + '/images'\n",
    "    sub_dataset['images'], sub_dataset['annotations'] = images_annotations_info(IMAGE_PATH, MASK_PATH, keyword, 0 * 100000, False)\n",
    "    with open(ORIGIN_PATH + '/annotations/pseudo_' + '{}'.format(keyword) + '.json', 'w') as outfile:\n",
    "        json.dump(sub_dataset, outfile)\n",
    "    print(str(keyword) + ': END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('mmdetection': conda)",
   "language": "python",
   "name": "python361164bitmmdetectioncondac5e20e32b3c64899be2ee20da743e85a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
