\documentclass[journal]{IEEEtran}
\usepackage{graphicx}
\usepackage{cite}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{Bare Demo of IEEEtran.cls\\ for IEEE Journals}

\author{Ruoning Song,~\IEEEmembership{Student Member,~IEEE,}
        Chuang Zhu,~\IEEEmembership{Member,~IEEE,}
        Jun Liu,~\IEEEmembership{Member,~IEEE,}\\        
        Jie Yang,~\IEEEmembership{Member,~IEEE,}        
        and~Tong~Zhang% <-this % stops a space
\thanks{Ruoning Song, Chuang Zhu, Jun Liu and Jie Yang was with Beijing University of Posts and Telecommunications, Beijing, 100876 China (e-mail: songrn,czhu,liujun,janeyang@bupt.edu.cn).}% <-this % stops a space
\thanks{J. Doe and J. Doe are with Ultrasonic Medical Center of Chenzhou No.1 People's Hospital, Chenzhou, China (e-mail: 18973575600@189.cn).}% <-this % stops a space
\thanks{Manuscript received April 19, 2005; revised August 26, 2015.}}


% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
The abstract goes here.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
IEEE, IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}

% \IEEEpeerreviewmaketitle

\section{Introduction}
\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter file''
for IEEE journal papers produced under \LaTeX\ using
IEEEtran.cls version 1.8b and later.
 
I wish you the best of success.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol
\section{Related work}\label{section_related_work}

The increasing popularity and diversification of Internet services, such as social networking, instant messaging, forums, online videos, and online e-commerce sites, have made UIL problems receive increasing attention [3]. Usually, the goal of the UIL problem is to answer a simple question: do two online identities belong to the same real person? This question can be seen as a classification problem, which classifies the online identities belong to the same real person to the same class. In handling the classification tasks, the two main challenges are extracting representative features and constructing classifiers with good performance. In this section, we will summarize the previous studies according to these two aspects.

\subsubsection{Extracting Representative Features}

\subsubsection{Deep Learning on Ultrasound Image Segmentation}
Ultrasound studies are the non-invasive methods for internal organ visualization. They are widespread in many spheres of medicine [1], [2]. Modern technology provides a number of tools to access myocardial function with using ultrasound. Echocardography (EchoCG) is widely used for the diagnosis of cardiac diseases since it presents several advantages when compared to other imaging techniques: the cost of an exam is relatively low; no specific preparation of the patient is required and the exam can take place at the patients bed; it is non invasive and does not present any hazard for the patient; the acquisition rate is very high. In the context of echocardiography, the extraction and analysis of the evolution of heart function parameters (such as the end diastolic/systolic volume, ejection fraction, strain, strain rate and etc.) throughout the cardiac cycle represent a strong clinical need and provide valuable information during an exam. However, this relies on the segmentation of the myocardial border which is usually manually or semi-automatically drawn by a cardiologist (Fig. 1). This yields subjective interpretation of the data as well as high inter and intraobserver variability due the quality of the data. Automatic segmentation tools for EchoCG data are thus highly needed in order to provide these parameters in an objective, fast and reproducible manner. Consequently EchoCG image segmentation is a very active research domain. it is prone to poor repeatability.
There are a lot of studies for development automatic algorithms for segmentation the left ventricular (LV) area on ultrasound images [3]â€“[9] despite existing guidelines of the American Society of Echocardiography [10] which contains the set of rules developed by experts for conducting ultrasound studies of the heart. The rules do not allow to generalize the expert experience. Thus, the issue of an automatic segmentation and tracking of the LV on EchoCG images is an practical and actual problem. For solving the problem we propose to use methods of pixel classification in the image using multilayer convolutional neural networks (CNN). This CNN is trained on a set of labeled data and produces a probabilistic mask with the probabilities of the pixel belonging to the LV area. 

Subsubsection text here.

\section{Methods}

\section{Experiments}

\subsection{Datasets}

The thyroid nodule ultrasound images used in our research work were from the following two datasets, one is from the Ultrasonic Medical Center of Chenzhou No.1 People's Hospital, called local dataset, and another is from a , called public dataset.

\subsubsection{Public Dataset}

The Digital Database of Thyroid Ultrasound Images (DDTI) \cite{pedraza2015open} are adopted in the experiments. DDTI consists of a set of B-mode Ultrasound images, including a complete annotation and diagnostic description of suspicious thyroid lesions by at least two expert radiologists. Currently, DDTI contains 299 cases (270 women and 29 men) with 347 images. All of the cases with relevant thyroid disorders were collected from the IDIME Ultrasound Department, one of the largest diagnostic imaging centers in Colombia. Ultrasound images were extracted from thyroid ultrasound video sequences captured by Ultrasound devices (TOSHIBA Nemio 30/TOSHIBA Nemio MX). Ultrasound images were saved in an uncompressed JPEG format. The nodule polygon and annotation information were saved in an alone XML file per one patient. The patients were classified by the experts using the thyroid imaging, reporting and data system (TI-RADS) \cite{tessler2017acr}. TI-RADS give points for all features of five ultrasound categories in a nodule, with more suspicious features being awarded additional points. TI-RADS scores sums feature points of all the categories, which range from TR1 (benign) to TR5 (high suspicion of malignancy). These TI-RADS descriptions were also included in the XML file.

\subsubsection{Local Dataset}

Another database is a local database, consisting of 377 thyroid ultrasound images which images are with the sizes 1024$\times$695. 269 images in the database are labeled as malignant, and 108 cases are labeled as benign. This database is collected by the Ultrasonic Medical Center of Chenzhou No.1 People's Hospital. The nodule polygon and annotation information were also saved in an alone XML file per one patient.

\section{Conclusion}
The conclusion goes here.





% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...

\cite{IEEEexample:biblatex}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,IEEEexample}

\begin{IEEEbiography}{Michael Shell}
Biography text here.
\end{IEEEbiography}

\end{document}


